#  AI Coding Assistant Instructions

## Project Overview
This is a comprehensive **Real Estate Price Prediction** project for the **Master's in Applied Economics (UBA)**. The project implements a complete ML/NLP pipeline using Jupyter notebooks with sequential data processing and progressive model complexity.

##  Project Architecture

### Data Pipeline Flow
`
train_bi_2025.csv  [01_exploratory]  train_bi_2025_filtered.csv  [02,03,04_models]  predictions
`

### Notebook Sequence (MUST execute in order)
1. **01_analisis_exploratorio.ipynb** - EDA, outlier removal, feature engineering
2. **02_modelos_tradicionales.ipynb** - Linear regression, LASSO (baseline)
3. **03_modelos_ml.ipynb** - Random Forest, XGBoost, Neural Networks
4. **04_modelos_nlp.ipynb** - NLP + hybrid models with text analysis

### Critical Data Dependencies
- 	rain_bi_2025_filtered.csv is generated by notebook 01 and consumed by notebooks 02-04
- **Never skip notebook 01** - subsequent notebooks depend on its data preprocessing
- Original 	rain_bi_2025.csv has 100K+ rows, filtered version has ~85K rows

##  Core Coding Patterns

### Standard Imports Template
`python
# Essential for all notebooks
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# Visualization setup
plt.style.use('seaborn-v0_8')
plt.rcParams['figure.figsize'] = (12, 8)
sns.set_palette("husl")
`

### Data Loading Pattern
`python
# Always load the filtered dataset for modeling (notebooks 02-04)
df = pd.read_csv('train_bi_2025_filtered.csv')
print(" Dataset filtrado y optimizado cargado")
print(f" Dimensiones: {df.shape[0]:,} filas  {df.shape[1]} columnas")
`

### Memory-Efficient NLP Processing
`python
# For large text processing - Use vocabulary limits
from sklearn.feature_extraction.text import TfidfVectorizer

# CRITICAL: Always limit vocabulary for memory efficiency
vectorizer = TfidfVectorizer(
    max_features=5000,  # Prevent memory overflow
    stop_words='spanish',
    ngram_range=(1, 2),
    min_df=2
)
`

##  Critical Memory Management

### Word2Vec Memory Issue (FIXED)
**Problem**: Original Word2Vec created 309K309K matrix (714 GB RAM)
**Solution**: Vocabulary limitation + efficient sampling
`python
# GOOD: Memory-efficient Word2Vec
from gensim.models import Word2Vec

# Limit vocabulary and dimensions
model = Word2Vec(
    sentences=processed_descriptions,
    vector_size=100,        # Reduced from 300
    window=5,
    min_count=5,           # Increased threshold
    max_vocab_size=5000,   # CRITICAL: Vocabulary limit
    workers=4
)
`

### TF-IDF Best Practices
`python
# Always use max_features to prevent memory overflow
vectorizer = TfidfVectorizer(
    max_features=5000,     # NEVER exceed without memory check
    stop_words='spanish',
    min_df=2,             # Remove rare words
    max_df=0.95           # Remove common words
)
`

##  Academic Requirements

### Evaluation Criteria (80/100 achieved)
- **Exploratory Analysis**: Comprehensive EDA with statistical insights
- **Traditional Models**: Economic interpretation of coefficients
- **ML Models**: Hyperparameter optimization + overfitting analysis
- **NLP Models**: Text preprocessing + hybrid feature engineering
- **Documentation**: Clear methodology and business insights

### Required Model Types
1. **Linear Regression** - Baseline with coefficient interpretation
2. **LASSO** - Feature selection and regularization
3. **Random Forest** - Non-linear relationships + feature importance
4. **XGBoost** - Gradient boosting optimization
5. **Neural Networks** - Deep learning approach
6. **NLP Models** - TF-IDF, Word2Vec, sentiment analysis

### Business Context
- **Target**: Real estate price prediction in Argentine market
- **Features**: Location, property characteristics, market conditions, text descriptions
- **Goal**: Interpretable models for economic analysis + predictive accuracy

##  Development Guidelines

### Code Style
- Use descriptive Spanish comments for academic context
- Include progress indicators: print(" Step completed")
- Add emoji indicators for different sections:    
- Always show data dimensions after loading/processing

##  Common Tasks

### Adding New Models
1. Follow the evaluation template pattern
2. Include both train/test metrics
3. Add feature importance analysis if applicable
4. Compare against existing baselines
5. Document business interpretation

### Text Preprocessing
`python
# Standard Spanish text preprocessing
import re

def preprocess_spanish_text(text):
    """Standard text preprocessing for Spanish real estate descriptions"""
    if pd.isna(text):
        return ""
    
    # Convert to lowercase and remove special characters
    text = str(text).lower()
    text = re.sub(r'[^\w\s]', ' ', text)
    text = re.sub(r'\d+', ' ', text)  # Remove numbers
    text = ' '.join(text.split())     # Remove extra whitespace
    
    return text
`

##  Performance Benchmarks

### Expected Results
- **Linear Regression**: R ~0.65
- **LASSO**: R ~0.67 (with feature selection)
- **Random Forest**: R ~0.75-0.80
- **XGBoost**: R ~0.80-0.85
- **Neural Networks**: R ~0.75-0.80
- **NLP Hybrid**: R improvement of 2-5%

### Optimization Targets
- **Training time**: <10 minutes per model on standard hardware
- **Memory usage**: <8GB RAM for largest operations
- **Prediction accuracy**: RMSE <,000 ARS for test set

##  Debugging Common Issues

### Memory Errors
1. Reduce max_features in vectorizers
2. Use max_vocab_size in Word2Vec
3. Implement batch processing for large datasets
4. Clear intermediate variables with del variable

### Poor Model Performance
1. Check data leakage (lat/lon in features)
2. Verify categorical encoding (use pd.get_dummies)
3. Scale numerical features for neural networks
4. Cross-validate hyperparameters

### Notebook Execution Issues
1. Always run notebooks in sequence (01020304)
2. Verify 	rain_bi_2025_filtered.csv exists before running 02-04
3. Check memory usage before large operations
4. Clear output/restart kernel if performance degrades

##  Key Libraries & Versions
- pandas, numpy, scikit-learn (latest)
- XGBoost, matplotlib, seaborn
- gensim (for Word2Vec)
- tqdm (for progress bars)
- Spanish NLP: Use scikit-learn with 'spanish' stop words

This project demonstrates production-ready ML pipeline development with academic rigor and business applicability. Focus on interpretability, efficiency, and comprehensive evaluation when making modifications.
