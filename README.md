# ğŸ  Trabajo Final - Inteligencia de Negocios 2025

**MaestrÃ­a en EconomÃ­a Aplicada - Facultad de Ciencias EconÃ³micas - UBA**

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un sistema completo de **predicciÃ³n de precios de inmuebles** utilizando tÃ©cnicas de Machine Learning y Procesamiento de Lenguaje Natural (NLP). El objetivo es predecir el precio de propiedades basÃ¡ndose en caracterÃ­sticas numÃ©ricas, categÃ³ricas y descripciones textuales.

## ğŸ—‚ï¸ Estructura del Proyecto

### ğŸ“ Archivos de Datos
- `train_bi_2025.csv` - Dataset de entrenamiento original (~400k registros)
- `test_bi_2025.csv` - Dataset de prueba para evaluaciÃ³n final
- `train_bi_2025_filtered.csv` - Dataset filtrado (generado automÃ¡ticamente)

### ğŸ““ Notebooks del AnÃ¡lisis

#### 1. **01_analisis_exploratorio.ipynb** ğŸ”
**DuraciÃ³n estimada:** 10-15 minutos
- âœ… Carga y exploraciÃ³n inicial del dataset
- âœ… AnÃ¡lisis de tipos de datos y valores faltantes
- âœ… Matriz de correlaciones y estadÃ­sticas descriptivas
- âœ… AnÃ¡lisis por tipo de propiedad con visualizaciones
- âœ… DetecciÃ³n y eliminaciÃ³n de outliers (mÃ©todo IQR)
- âœ… OptimizaciÃ³n de variables temporales para ML
- âœ… GeneraciÃ³n de dataset filtrado y optimizado

#### 2. **02_modelos_tradicionales.ipynb** ğŸ“ˆ
**DuraciÃ³n estimada:** 5-10 minutos
- âœ… PreparaciÃ³n de datos con encoding automÃ¡tico
- âœ… **RegresiÃ³n Lineal:** AnÃ¡lisis de coeficientes y significancia
- âœ… **LASSO:** OptimizaciÃ³n con validaciÃ³n cruzada, selecciÃ³n de variables
- âœ… InterpretaciÃ³n econÃ³mica de coeficientes
- âœ… AnÃ¡lisis de significatividad estadÃ­stica vs prÃ¡ctica
- âœ… ComparaciÃ³n final con visualizaciones

#### 3. **03_modelos_ml.ipynb** ğŸ¤–
**DuraciÃ³n estimada:** 15-25 minutos
- âœ… **Random Forest:** OptimizaciÃ³n con RandomizedSearchCV
- âœ… **XGBoost:** ConfiguraciÃ³n optimizada con verbose para seguimiento
- âœ… **Redes Neuronales (MLP):** Arquitecturas optimizadas
- âœ… **AnÃ¡lisis de overfitting:** ClasificaciÃ³n de robustez
- âœ… Importancia de variables y visualizaciones
- âœ… ComparaciÃ³n con mÃ©tricas de generalizaciÃ³n

#### 4. **04_modelos_nlp.ipynb** ğŸ“
**DuraciÃ³n estimada:** 15-25 minutos
- âœ… **Procesamiento de texto:** Limpieza con stopwords en espaÃ±ol
- âœ… **TF-IDF + SVD:** ReducciÃ³n dimensional (5000â†’300 componentes)
- âœ… **Modelos hÃ­bridos:** CombinaciÃ³n de features tradicionales + texto
- âœ… **Random Forest NLP:** OptimizaciÃ³n con HalvingRandomSearchCV
- âœ… **XGBoost NLP:** OptimizaciÃ³n avanzada con GPU
- âœ… **Redes Neuronales NLP:** 3 arquitecturas diferentes (PyTorch GPU)
- âœ… **AnÃ¡lisis de tÃ©rminos:** Palabras mÃ¡s predictivas del precio
- âœ… **ComparaciÃ³n integral:** Modelos con y sin texto

#### 5. **06_evaluacion_final_performance.ipynb** ğŸ“Š
**DuraciÃ³n estimada:** 5-10 minutos
- âœ… **Consigna 6:** EvaluaciÃ³n de 6 modelos optimizados sobre test
- âœ… **AnÃ¡lisis comparativo:** Modelos con vs sin descripciones
- âœ… **MÃ©tricas RMSE y MAE:** Reportes detallados
- âœ… **Conclusiones:** InformaciÃ³n relevante en descripciones de texto
- âœ… **Visualizaciones:** GrÃ¡ficos comparativos de performance

## ğŸš€ CÃ³mo Ejecutar el Proyecto

### OpciÃ³n 1: EjecuciÃ³n Secuencial (Recomendada)
```bash
1. Ejecutar: 01_analisis_exploratorio.ipynb
2. Ejecutar: 02_modelos_tradicionales.ipynb
3. Ejecutar: 03_modelos_ml.ipynb
4. Ejecutar: 04_modelos_nlp.ipynb
5. Ejecutar: 06_evaluacion_final_performance.ipynb
```

### OpciÃ³n 2: EjecuciÃ³n Independiente
Cada notebook es **auto-contenida** y puede ejecutarse independientemente. Cada una carga y prepara sus propios datos.

## ğŸ“¦ Dependencias

### LibrerÃ­as Requeridas:
```python
pandas>=1.3.0
numpy>=1.21.0
matplotlib>=3.4.0
seaborn>=0.11.0
scikit-learn>=1.0.0
xgboost>=1.5.0
tqdm>=4.62.0
```

### InstalaciÃ³n:
```bash
pip install pandas numpy matplotlib seaborn scikit-learn xgboost tqdm
```

## ğŸ“Š Resultados Obtenidos

### ğŸ¯ Mejores Modelos por CategorÃ­a:

| CategorÃ­a | Mejor Modelo | RMSE | RÂ² | MAE | Features | Overfitting |
|-----------|-------------|------|----|----|---------|-------------|
| **Tradicional** | RegresiÃ³n Lineal | $42,960 | 0.7285 | $30,922 | 93 | 0.991 âœ… |
| **Machine Learning** | XGBoost Optimizado | $34,623 | 0.8236 | $23,967 | 93 | 1.076 âœ… |
| **NLP HÃ­brido** | **XGBoost NLP** | **$26,471** | **0.8982** | **$17,284** | **393** | **1.487 âš ï¸** |

### ğŸ† **Modelo Ganador: XGBoost NLP**
- **RMSE:** $26,471 (mejor rendimiento absoluto)
- **RÂ²:** 0.8982 (explica 89.8% de la variabilidad)
- **MAE:** $17,284 (error absoluto medio mÃ¡s bajo)
- **Overfitting Ratio:** 1.487 (overfitting moderado pero aceptable)
- **Features:** 393 (93 tradicionales + 300 texto TF-IDF/SVD)
- **Mejora vs XGBoost tradicional:** 23.5% en RMSE

### ğŸ“ˆ **Ranking Completo de Modelos (Top 8)**:
1. **XGBoost NLP** - $26,471 RMSE, RÂ² 0.8982, MAE $17,284 âš ï¸
2. **Red Neuronal NLP Simple** - $28,193 RMSE, RÂ² 0.8845, MAE $19,013 âœ…
3. **Random Forest NLP** - $29,900 RMSE, RÂ² 0.8701, MAE $19,455 âŒ
4. **XGBoost Optimizado** - $34,623 RMSE, RÂ² 0.8236, MAE $23,967 âœ…
5. **Red Neuronal NLP EstÃ¡ndar** - $35,097 RMSE, RÂ² 0.8210, MAE $24,640 âœ…
6. **Red Neuronal Optimizada** - $40,321 RMSE, RÂ² 0.7608, MAE $28,231 âœ…
7. **Random Forest Optimizado** - $40,837 RMSE, RÂ² 0.7547, MAE $28,963 âœ…
8. **RegresiÃ³n Lineal** - $42,960 RMSE, RÂ² 0.7285, MAE $30,922 âœ…

## ğŸ” CaracterÃ­sticas del Dataset

### Variables Principales:
- **NumÃ©ricas:** rooms, bathrooms, surface_total, surface_covered
- **Temporales:** created_year, created_month, created_quarter, created_weekday
- **CategÃ³ricas:** l2, l3, prop_type  
- **Texto:** description (procesada con TF-IDF + SVD)
- **Target:** price

### Procesamiento:
- **Dataset original:** 400k+ registros
- **Dataset filtrado:** 311,660 registros (eliminaciÃ³n de outliers IQR)
- **Features tradicionales:** 93 (post one-hot encoding)
- **Features de texto:** 300 (post SVD de 5,000 tÃ©rminos TF-IDF)
- **Features hÃ­bridas:** 393 (tradicionales + texto)

## âš¡ Optimizaciones Implementadas

### Rendimiento:
- âœ… **HalvingRandomSearchCV** para bÃºsqueda eficiente de hiperparÃ¡metros
- âœ… **PyTorch GPU** para redes neuronales aceleradas
- âœ… **SVD** para reducciÃ³n dimensional del texto (5000â†’300)
- âœ… **Early stopping** en redes neuronales
- âœ… **Memory management** para datasets grandes

### Robustez:
- âœ… **AnÃ¡lisis de overfitting:** ClasificaciÃ³n automÃ¡tica por ratios
- âœ… **ValidaciÃ³n cruzada** en optimizaciÃ³n de hiperparÃ¡metros
- âœ… **MÃ©tricas mÃºltiples:** RMSE, RÂ², MAE, ratios de generalizaciÃ³n
- âœ… **ComparaciÃ³n integral:** 8+ modelos evaluados
- âœ… **EvaluaciÃ³n separada:** Train, validaciÃ³n y test independientes

## ğŸ“ˆ Insights Clave

### Variables MÃ¡s Importantes (Modelos Tradicionales):
1. **surface_total** - Superficie total (coef: +$49,878 por mÂ²)
2. **bathrooms** - NÃºmero de baÃ±os (coef: +$13,806 por baÃ±o)
3. **rooms** - NÃºmero de habitaciones (coef: +$5,618 por habitaciÃ³n)
4. **l3_Puerto Madero** - UbicaciÃ³n premium (coef: +$178,390)
5. **l3_Villa Soldati** - UbicaciÃ³n desfavorable (coef: -$86,924)

### Variables MÃ¡s Importantes (Modelos NLP):
1. **trad_surface_covered** - Superficie cubierta (34.1% importancia RF)
2. **trad_surface_total** - Superficie total (20.3% importancia RF)
3. **trad_l3_Puerto Madero** - UbicaciÃ³n premium (6.1% importancia XGB)
4. **texto_dim_12** - DimensiÃ³n textual 12 (4.8% importancia RF)
5. **trad_bathrooms** - NÃºmero de baÃ±os (6.3% importancia RF)

### Impacto del NLP:
- âœ… **XGBoost:** 23.5% mejora en RMSE con texto
- âœ… **Red Neuronal Simple:** 30.1% mejora en RMSE con texto  
- âœ… **Random Forest:** 20.4% mejora en RMSE con texto
- âœ… **ContribuciÃ³n promedio:** ~25% mejora en performance
- âœ… **InformaciÃ³n valiosa:** Las descripciones SÃ contienen informaciÃ³n relevante

### AnÃ¡lisis de Overfitting (ClasificaciÃ³n por Ratios):
- âœ… **Excelente (â‰¤1.05):** Red Neuronal NLP EstÃ¡ndar (1.007)
- âœ… **Bueno (â‰¤1.15):** XGBoost Optimizado (1.076), Red Neuronal Optimizada (0.992)
- âš ï¸ **Moderado (â‰¤1.50):** XGBoost NLP (1.487)
- âŒ **Severo (>1.50):** Random Forest NLP (1.686)

## ğŸ¯ Aplicaciones PrÃ¡cticas

### Para el Negocio:
- ğŸ  **Sistema de valuaciÃ³n automÃ¡tica** (error tÃ­pico $26,471)
- ğŸ“Š **DetecciÃ³n de precios anÃ³malos** (RÂ² 0.898)
- ğŸ“ˆ **Dashboard de monitoreo** por barrio/tipo de propiedad
- ğŸ¤– **RecomendaciÃ³n de precios** basada en descripciÃ³n textual
- ğŸ’¬ **AnÃ¡lisis de texto:** IdentificaciÃ³n de tÃ©rminos que incrementan valor

### Para Inversores:
- ğŸ’° **IdentificaciÃ³n de oportunidades** (modelo vs mercado)
- ğŸ“Š **AnÃ¡lisis de mercado** por zona geogrÃ¡fica (l2, l3)
- ğŸ” **EvaluaciÃ³n de propiedades** con descripciones optimizadas
- ğŸ“ˆ **PredicciÃ³n de ROI** basada en caracterÃ­sticas textuales

### Para Desarrolladores:
- ğŸ—ï¸ **OptimizaciÃ³n de descripciones** para maximizar valor percibido
- ğŸ“ **Guidelines de marketing** basadas en tÃ©rminos mÃ¡s influyentes
- ğŸ¯ **SegmentaciÃ³n de mercado** por preferencias textuales

## ğŸ”¬ MetodologÃ­a TÃ©cnica

### AnÃ¡lisis de Overfitting (Ratios train/test RMSE):
- **Excelente (â‰¤1.05):** GeneralizaciÃ³n perfecta
- **Bueno (â‰¤1.15):** GeneralizaciÃ³n aceptable  
- **Moderado (â‰¤1.50):** Overfitting controlado
- **Severo (>1.50):** Overfitting problemÃ¡tico

### Procesamiento NLP:
- **Limpieza:** Texto espaÃ±ol, stopwords personalizadas + inmobiliarias
- **VectorizaciÃ³n:** TF-IDF con unigramas y bigramas (max_features=5000)
- **ReducciÃ³n:** SVD 5000â†’300 dimensiones (retiene >80% varianza)
- **CombinaciÃ³n:** Features tradicionales (93) + texto (300) = 393 totales
- **Memoria:** OptimizaciÃ³n para datasets grandes con batch processing

### OptimizaciÃ³n de HiperparÃ¡metros:
- **Random Forest:** HalvingRandomSearchCV con resource=n_estimators
- **XGBoost:** HalvingRandomSearchCV + early stopping
- **Redes Neuronales:** PyTorch con GPU, 3 arquitecturas diferentes
- **ValidaciÃ³n:** 2-fold CV para eficiencia en datasets grandes

## ğŸ”œ Trabajo Futuro

1. **Embeddings avanzados:** Word2Vec, FastText, BERT en espaÃ±ol
2. **AnÃ¡lisis de sentimientos:** Polaridad y emociones en descripciones
3. **GeolocalizaciÃ³n:** Features basadas en coordenadas lat/lon
4. **Ensemble methods:** Stacking de mejores modelos (XGB NLP + NN Simple)
5. **OptimizaciÃ³n de memoria:** Streaming para datasets >1M registros
6. **Transfer learning:** Modelos pre-entrenados en espaÃ±ol inmobiliario
7. **Feature engineering:** Interacciones texto-numÃ©ricas automÃ¡ticas
8. **Deployment:** API REST para predicciones en tiempo real

## ğŸ† RecomendaciÃ³n Final

### **Modelo Recomendado para ProducciÃ³n:**
**XGBoost NLP** ($26,471 RMSE, RÂ² 0.8982, MAE $17,284)

**JustificaciÃ³n:**
- âœ… **Mejor rendimiento:** 38% mejor que modelos tradicionales
- âš ï¸ **Overfitting moderado:** 1.487 ratio (aceptable para el rendimiento obtenido)
- âœ… **Escalabilidad:** Maneja bien 393 features hÃ­bridas
- âœ… **Interpretabilidad:** Feature importance clara y explicable
- âœ… **Aplicabilidad:** Funciona con y sin descripciÃ³n de texto
- âœ… **ROI:** Reduce error de predicciÃ³n significativamente vs alternativas

### **Modelo Alternativo Robusto:**
**Red Neuronal NLP Simple** ($28,193 RMSE, RÂ² 0.8845)
- âœ… **Excelente generalizaciÃ³n:** Sin overfitting
- âœ… **Performance sÃ³lida:** 2Â° mejor modelo
- âœ… **Estabilidad:** Ideal para ambientes conservadores

### **Estrategia HÃ­brida Recomendada:**
1. **ProducciÃ³n principal:** XGBoost NLP (mÃ¡ximo rendimiento)
2. **ValidaciÃ³n cruzada:** Red Neuronal Simple (robustez)
3. **Fallback:** XGBoost tradicional (cuando falta descripciÃ³n)

## ğŸ‘¥ InformaciÃ³n del Curso

- **Materia:** Inteligencia de Negocios
- **InstituciÃ³n:** MaestrÃ­a en EconomÃ­a Aplicada - UBA
- **AÃ±o:** 2025
- **Formato entrega:** Jupyter Notebooks ejecutados

---